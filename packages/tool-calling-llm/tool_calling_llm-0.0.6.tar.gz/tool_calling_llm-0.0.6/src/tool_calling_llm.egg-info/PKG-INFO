Metadata-Version: 2.1
Name: tool_calling_llm
Version: 0.0.6
Summary: Convert any LangChain Chat Model into a Tool Calling LLM
Author-email: Karim Lalani <jimmy00784@gmail.com>
Project-URL: Homepage, https://github.com/lalanikarim/tool_calling_llm
Project-URL: Issues, https://github.com/lalanikarim/tool_calling_llm/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: langchain>=0.2.12
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: langchain-community>=0.2.11; extra == "test"
Requires-Dist: langchain-ollama; extra == "test"
Requires-Dist: litellm; extra == "test"
Requires-Dist: xmltodict; extra == "test"
Requires-Dist: duckduckgo_search; extra == "test"

Tool Calling LLM
================

Tool Calling LLM is a python mixin that lets you add tool calling capabilities effortlessly to LangChain Chat Models that don't yet support tool/function calling natively. Simply create a new chat model class with ToolCallingLLM and your favorite chat model to get started.

With ToolCallingLLM you also get access to .with_structured_output() which will allow you to return structured data from your model.

At this time, ToolCallingLLM has been tested to work with ChatNVIDIA and ChatLiteLLM with Ollama provider.

The OllamaFunctions was the original inspiration for this effort. The code for ToolCallingLLM was abstracted out of OllamaFunctions to allow it to be reused with other non tool calling Chat Models.
