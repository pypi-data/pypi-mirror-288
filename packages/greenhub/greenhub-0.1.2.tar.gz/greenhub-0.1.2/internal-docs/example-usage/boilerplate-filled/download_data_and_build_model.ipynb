{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example Model for Wheat Yield in AR, Santa Fe using Greenhub SDK\n",
    "## Features: VI, Soil, Climate"
   ],
   "id": "8b7fd852c5edee0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:23.914403Z",
     "start_time": "2024-08-02T08:44:23.910925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import greenhub as gh\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ],
   "id": "1136143bf3ccdf4a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Fetch Data",
   "id": "e3fa63c84c96fdbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:25.297876Z",
     "start_time": "2024-08-02T08:44:24.931901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize greenhub sdk\n",
    "gh.initialize(\"RejhCxnCdTKwDX1zK2lqIB24e1bBAAZk\")"
   ],
   "id": "878c8f1fbf003658",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load Historical Yield Data (Training Targets)\n",
    "\n",
    "Note that the yield data is loaded from local storage. The Greenhub SDK will soon provide a method `get_yield_data()` to fetch the yield data on our Firebase Storage."
   ],
   "id": "396a3e651093c503"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:26.285749Z",
     "start_time": "2024-08-02T08:44:26.253910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Wheat Yield Data\n",
    "dfs = []\n",
    "for root, dirs, files in os.walk('./historical-yield-data/AR/targets/states'):\n",
    "    for file in tqdm(files):\n",
    "        if file.endswith('yield_states_normalized.csv'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            year = df['Year']\n",
    "            dfs.append(df)\n",
    "\n",
    "wheat_df = pd.concat(dfs, ignore_index=True)\n",
    "wheat_df = wheat_df[['Year', 'State', 'Value']]\n",
    "wheat_df['Year'] = pd.to_numeric(wheat_df['Year'])\n",
    "wheat_df"
   ],
   "id": "1c379f9439787eca",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m             year \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      9\u001B[0m             dfs\u001B[38;5;241m.\u001B[39mappend(df)\n\u001B[0;32m---> 11\u001B[0m wheat_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdfs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m wheat_df \u001B[38;5;241m=\u001B[39m wheat_df[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValue\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m     13\u001B[0m wheat_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(wheat_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/miniconda3/envs/L/lib/python3.9/site-packages/pandas/core/reshape/concat.py:382\u001B[0m, in \u001B[0;36mconcat\u001B[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[1;32m    380\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 382\u001B[0m op \u001B[38;5;241m=\u001B[39m \u001B[43m_Concatenator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjoin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[0;32m~/miniconda3/envs/L/lib/python3.9/site-packages/pandas/core/reshape/concat.py:445\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverify_integrity \u001B[38;5;241m=\u001B[39m verify_integrity\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy \u001B[38;5;241m=\u001B[39m copy\n\u001B[0;32m--> 445\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_clean_keys_and_objs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[1;32m    448\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n",
      "File \u001B[0;32m~/miniconda3/envs/L/lib/python3.9/site-packages/pandas/core/reshape/concat.py:507\u001B[0m, in \u001B[0;36m_Concatenator._clean_keys_and_objs\u001B[0;34m(self, objs, keys)\u001B[0m\n\u001B[1;32m    504\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(objs)\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 507\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo objects to concatenate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    510\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(com\u001B[38;5;241m.\u001B[39mnot_none(\u001B[38;5;241m*\u001B[39mobjs_list))\n",
      "\u001B[0;31mValueError\u001B[0m: No objects to concatenate"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 Load Feature Data",
   "id": "f3495e0fdc3f71b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### VI Data",
   "id": "2131062b9bc4f6fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:54.399231Z",
     "start_time": "2024-08-02T08:44:28.162528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch VI data\n",
    "vi_df = gh.get_vi_data(country='AR', start_year=2010, end_year=2023, spatial_resolution='state')\n",
    "vi_df"
   ],
   "id": "461bb99c4d828e28",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading VI data:   0%|          | 0/168 [00:00<?, ?items/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "100c958333874dfda45ee29b2f0f1931"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "          FPAR       EVI      NDVI         ENGTYPE_1 CountryCode  NL_NAME_1  \\\n",
       "0     0.460023  0.350348  0.522568          Province          AR        NaN   \n",
       "1     0.561885  0.400193  0.602391          Province          AR        NaN   \n",
       "2     0.606848  0.426762  0.689785          Province          AR        NaN   \n",
       "3     0.516521  0.404217  0.618911          Province          AR        NaN   \n",
       "4     0.544842  0.447910  0.604574          Province          AR        NaN   \n",
       "...        ...       ...       ...               ...         ...        ...   \n",
       "4027  0.399891  0.295253  0.473935          Province          AR        NaN   \n",
       "4028  0.366476  0.258074  0.415640          Province          AR        NaN   \n",
       "4029  0.348616  0.321998  0.482641          Province          AR        NaN   \n",
       "4030       NaN       NaN       NaN          Province          AR        NaN   \n",
       "4031       NaN       NaN       NaN  Federal District          AR        NaN   \n",
       "\n",
       "     HASC_1 ISO_1  CC_1     GID_1                         VARNAME_1  \\\n",
       "0     AR.CT  AR-K   NaN   ARG.2_1                               NaN   \n",
       "1     AR.CH  AR-U   NaN   ARG.4_1                               NaN   \n",
       "2     AR.CN  AR-W   NaN   ARG.7_1                               NaN   \n",
       "3     AR.FM  AR-P   NaN   ARG.9_1                               NaN   \n",
       "4     AR.JY  AR-Y   NaN  ARG.10_1                               NaN   \n",
       "...     ...   ...   ...       ...                               ...   \n",
       "4027  AR.BA  AR-B   NaN   ARG.1_1               Baires|Buenos Ayres   \n",
       "4028  AR.LP  AR-L   NaN  ARG.11_1                El Pampa|Eva Perón   \n",
       "4029  AR.CC  AR-H   NaN   ARG.3_1    El Chaco|Presidente Juan Peron   \n",
       "4030  AR.TF  AR-V   NaN  ARG.23_1   Feuerland|Terra del Fuoco|Terre   \n",
       "4031  AR.DF   NaN   NaN   ARG.5_1  BUENOS AIRES D.F.|Capital Federa   \n",
       "\n",
       "                TYPE_1                   State  Year  Month  \n",
       "0            Provincia               CATAMARCA  2010      1  \n",
       "1            Provincia                  CHUBUT  2010      1  \n",
       "2            Provincia              CORRIENTES  2010      1  \n",
       "3            Provincia                 FORMOSA  2010      1  \n",
       "4            Provincia                   JUJUY  2010      1  \n",
       "...                ...                     ...   ...    ...  \n",
       "4027         Provincia            BUENOS AIRES  2023     12  \n",
       "4028         Provincia                LA PAMPA  2023     12  \n",
       "4029         Provincia                   CHACO  2023     12  \n",
       "4030         Provincia        TIERRA DEL FUEGO  2023     12  \n",
       "4031  Distrito Federal  CIUDAD DE BUENOS AIRES  2023     12  \n",
       "\n",
       "[4032 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FPAR</th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>ENGTYPE_1</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>NL_NAME_1</th>\n",
       "      <th>HASC_1</th>\n",
       "      <th>ISO_1</th>\n",
       "      <th>CC_1</th>\n",
       "      <th>GID_1</th>\n",
       "      <th>VARNAME_1</th>\n",
       "      <th>TYPE_1</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.460023</td>\n",
       "      <td>0.350348</td>\n",
       "      <td>0.522568</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.CT</td>\n",
       "      <td>AR-K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.2_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>CATAMARCA</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561885</td>\n",
       "      <td>0.400193</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.CH</td>\n",
       "      <td>AR-U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.4_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>CHUBUT</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.606848</td>\n",
       "      <td>0.426762</td>\n",
       "      <td>0.689785</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.CN</td>\n",
       "      <td>AR-W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.7_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>CORRIENTES</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.516521</td>\n",
       "      <td>0.404217</td>\n",
       "      <td>0.618911</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.FM</td>\n",
       "      <td>AR-P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.9_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>FORMOSA</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544842</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.604574</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.JY</td>\n",
       "      <td>AR-Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.10_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>JUJUY</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>0.399891</td>\n",
       "      <td>0.295253</td>\n",
       "      <td>0.473935</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.BA</td>\n",
       "      <td>AR-B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.1_1</td>\n",
       "      <td>Baires|Buenos Ayres</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>BUENOS AIRES</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>0.366476</td>\n",
       "      <td>0.258074</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.LP</td>\n",
       "      <td>AR-L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.11_1</td>\n",
       "      <td>El Pampa|Eva Perón</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>LA PAMPA</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4029</th>\n",
       "      <td>0.348616</td>\n",
       "      <td>0.321998</td>\n",
       "      <td>0.482641</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.CC</td>\n",
       "      <td>AR-H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.3_1</td>\n",
       "      <td>El Chaco|Presidente Juan Peron</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>CHACO</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Province</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.TF</td>\n",
       "      <td>AR-V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.23_1</td>\n",
       "      <td>Feuerland|Terra del Fuoco|Terre</td>\n",
       "      <td>Provincia</td>\n",
       "      <td>TIERRA DEL FUEGO</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Federal District</td>\n",
       "      <td>AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR.DF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ARG.5_1</td>\n",
       "      <td>BUENOS AIRES D.F.|Capital Federa</td>\n",
       "      <td>Distrito Federal</td>\n",
       "      <td>CIUDAD DE BUENOS AIRES</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4032 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:57.663264Z",
     "start_time": "2024-08-02T08:44:57.654852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Row selection, renaming etc.\n",
    "vi_df = vi_df[['EVI', 'NDVI', 'State', 'Year', 'Month']]\n",
    "vi_df['Year'] = pd.to_numeric(vi_df['Year'])\n",
    "vi_df[vi_df['State'] == 'SANTA FE']"
   ],
   "id": "3b6baf81f26e4a31",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/k4fp3yls1jl_ntlms33nvg4r0000gn/T/ipykernel_23709/3914539271.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  vi_df['Year'] = pd.to_numeric(vi_df['Year'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           EVI      NDVI     State  Year  Month\n",
       "17    0.591439  0.754725  SANTA FE  2010      1\n",
       "41    0.612505  0.792523  SANTA FE  2010      2\n",
       "65    0.459085  0.673373  SANTA FE  2010      3\n",
       "89    0.295464  0.466863  SANTA FE  2010      4\n",
       "113   0.249692  0.434951  SANTA FE  2010      5\n",
       "...        ...       ...       ...   ...    ...\n",
       "3929  0.291043  0.462785  SANTA FE  2023      8\n",
       "3953  0.292757  0.443480  SANTA FE  2023      9\n",
       "3977  0.254393  0.380690  SANTA FE  2023     10\n",
       "4001  0.258458  0.409775  SANTA FE  2023     11\n",
       "4025  0.369712  0.554704  SANTA FE  2023     12\n",
       "\n",
       "[168 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVI</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.591439</td>\n",
       "      <td>0.754725</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.612505</td>\n",
       "      <td>0.792523</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.459085</td>\n",
       "      <td>0.673373</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.295464</td>\n",
       "      <td>0.466863</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.249692</td>\n",
       "      <td>0.434951</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3929</th>\n",
       "      <td>0.291043</td>\n",
       "      <td>0.462785</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>0.292757</td>\n",
       "      <td>0.443480</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>0.254393</td>\n",
       "      <td>0.380690</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>0.258458</td>\n",
       "      <td>0.409775</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>0.369712</td>\n",
       "      <td>0.554704</td>\n",
       "      <td>SANTA FE</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Soil Data",
   "id": "1ba2571473f85c0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:44:58.664705Z",
     "start_time": "2024-08-02T08:44:58.649627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "req = {\n",
    "    'VI': ['EVI', 'NDVI'],\n",
    "    'Soil': ['D1_mean'],\n",
    "}\n",
    "\n",
    "gh.get_feature_vec(req, spatial_resolution='state', country='AR', start_year=2010, end_year=2023)"
   ],
   "id": "8d8d45c26925097e",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'greenhub' has no attribute 'get_feature_vec'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m req \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVI\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEVI\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNDVI\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSoil\u001B[39m\u001B[38;5;124m'\u001B[39m: [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mD1_mean\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      4\u001B[0m }\n\u001B[0;32m----> 6\u001B[0m \u001B[43mgh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_vec\u001B[49m(req, spatial_resolution\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate\u001B[39m\u001B[38;5;124m'\u001B[39m, country\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAR\u001B[39m\u001B[38;5;124m'\u001B[39m, start_year\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2010\u001B[39m, end_year\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2023\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'greenhub' has no attribute 'get_feature_vec'"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:00.213332Z",
     "start_time": "2024-08-02T08:44:59.669716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch soil data\n",
    "soil_df = gh.get_soil_data(country='AR', spatial_resolution='state', layer='D1')\n",
    "soil_df"
   ],
   "id": "ef2f9138e83b7ad9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading Soil data:   0%|          | 0/1 [00:00<?, ?items/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ecdf468cf844f0c97d0af1e5d10a61a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Fetch soil data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m soil_df \u001B[38;5;241m=\u001B[39m \u001B[43mgh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_soil_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcountry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAR\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspatial_resolution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mD1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m soil_df\n",
      "File \u001B[0;32m~/miniconda3/envs/L/lib/python3.9/site-packages/greenhub/data.py:327\u001B[0m, in \u001B[0;36mget_soil_data\u001B[0;34m(country, spatial_resolution, layer)\u001B[0m\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor the given parameters, no data can be retrieved. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    324\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor more information please checkout the official greenhub.ai documentation.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    326\u001B[0m \u001B[38;5;66;03m# load and fetch data as one combined dataframe\u001B[39;00m\n\u001B[0;32m--> 327\u001B[0m data, invalid_paths \u001B[38;5;241m=\u001B[39m _load_data(feature_files_paths, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSoil data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;66;03m# check if data is empty -> meaning that not at least one path worked\u001B[39;00m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:01.507248Z",
     "start_time": "2024-08-02T08:45:01.492329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Row selection, renaming etc.\n",
    "selected_cols = [col for col in soil_df.columns if (col.endswith('_avg') and not col.startswith('TP-')) or col in ['Layer', 'NAME_1']]\n",
    "soil_df = soil_df[selected_cols]\n",
    "soil_df.columns = soil_df.columns.str.replace('_avg', '')\n",
    "soil_df.rename({'NAME_1': 'State'}, axis=1, inplace=True)\n",
    "soil_df['State'] = soil_df['State'].apply(lambda x: x.upper())\n",
    "soil_df"
   ],
   "id": "d7575bd7e3c6b75c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soil_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Row selection, renaming etc.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m selected_cols \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[43msoil_df\u001B[49m\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m (col\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_avg\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m col\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTP-\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;129;01mor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLayer\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNAME_1\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m      3\u001B[0m soil_df \u001B[38;5;241m=\u001B[39m soil_df[selected_cols]\n\u001B[1;32m      4\u001B[0m soil_df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m soil_df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_avg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'soil_df' is not defined"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "soil_data['State'] = soil_data['State'].apply(lambda x: x.upper())### Climate Data (Temp, Prec, Solar)",
   "id": "f1088f4584da3386"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:28.440633Z",
     "start_time": "2024-08-02T08:45:02.773840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fetch climate data\n",
    "climate_df = gh.get_climate_data(country='AR', start_year=2010, end_year=2023, spatial_resolution='state')\n",
    "climate_df"
   ],
   "id": "78dbb9ab7a487d76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading Climate data:   0%|          | 0/168 [00:00<?, ?items/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19d2c9be9dc94e41ab5ce3ef5082ed21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Fetch climate data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m climate_df \u001B[38;5;241m=\u001B[39m \u001B[43mgh\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_climate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcountry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAR\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_year\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2010\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_year\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2023\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mspatial_resolution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m climate_df\n",
      "File \u001B[0;32m~/miniconda3/envs/L/lib/python3.9/site-packages/greenhub/data.py:261\u001B[0m, in \u001B[0;36mget_climate_data\u001B[0;34m(country, start_year, end_year, spatial_resolution, time_resolution)\u001B[0m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor the given parameters, no data can be retrieved. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    258\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFor more information please checkout the official greenhub.ai documentation.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    260\u001B[0m \u001B[38;5;66;03m# load and fetch data as one combined dataframe\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m data, invalid_paths \u001B[38;5;241m=\u001B[39m _load_data(feature_files_paths, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mClimate data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# check if data is empty -> meaning that not at least one path worked\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:30.067553Z",
     "start_time": "2024-08-02T08:45:30.054949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Row selection, renaming etc.\n",
    "climate_df = climate_df.drop(columns=['Unnamed: 0', 'Country'])\n",
    "climate_df['Year'] = pd.to_numeric(climate_df['Year'])\n",
    "climate_df"
   ],
   "id": "4b33f2cceb14b75b",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'climate_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Row selection, renaming etc.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m climate_df \u001B[38;5;241m=\u001B[39m \u001B[43mclimate_df\u001B[49m\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mUnnamed: 0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCountry\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      3\u001B[0m climate_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(climate_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      4\u001B[0m climate_df\n",
      "\u001B[0;31mNameError\u001B[0m: name 'climate_df' is not defined"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Merge all features",
   "id": "efeceab600f88dbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:31.457789Z",
     "start_time": "2024-08-02T08:45:31.442103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge\n",
    "merged_df = pd.merge(wheat_df, vi_df, on=['Year', 'State'], how='left')\n",
    "merged_df = pd.merge(merged_df, soil_df, on='State', how='left')\n",
    "merged_df = pd.merge(merged_df, climate_df, on=['Year', 'Month', 'State'], how='left')\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df"
   ],
   "id": "99a378843b928f22",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wheat_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Merge\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m merged_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(\u001B[43mwheat_df\u001B[49m, vi_df, on\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m], how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m merged_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(merged_df, soil_df, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m merged_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mmerge(merged_df, climate_df, on\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMonth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m], how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'wheat_df' is not defined"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:32.182269Z",
     "start_time": "2024-08-02T08:45:32.164969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a pivot table\n",
    "pivot_df = merged_df.pivot_table(index=['Year', 'State'], columns='Month', aggfunc='first')\n",
    "\n",
    "# Flatten the MultiIndex columns\n",
    "pivot_df.columns = ['{}_Month{}'.format(col[0], int(col[1])) for col in pivot_df.columns]\n",
    "\n",
    "# Reset index to turn MultiIndex into columns\n",
    "pivot_df.reset_index(inplace=True)\n",
    "\n",
    "# Fix 12x columns for static values\n",
    "squash_cols = ['Drain', 'CFRAG', 'SDTO', 'STPC', 'CLPC', 'BULK', 'TAWC','CECS', 'BSAT', 'ESP',\n",
    "               'CECc', 'PHAQ', 'TCEQ', 'GYPS', 'ELCO', 'ORGC', 'TOTN', 'CNrt', 'ECEC', 'ALSA', 'Value']\n",
    "pivot_df = pivot_df.rename({f'{squash}_Month1': f'{squash}' for squash in squash_cols}, axis=1)\n",
    "pivot_df = pivot_df.drop(columns=[col for col in pivot_df.columns if any(col.startswith(f'{squash}_Month') for squash in squash_cols)])\n",
    "\n",
    "pivot_df"
   ],
   "id": "fb2d200dab1f408e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create a pivot table\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m pivot_df \u001B[38;5;241m=\u001B[39m \u001B[43mmerged_df\u001B[49m\u001B[38;5;241m.\u001B[39mpivot_table(index\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m], columns\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMonth\u001B[39m\u001B[38;5;124m'\u001B[39m, aggfunc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfirst\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Flatten the MultiIndex columns\u001B[39;00m\n\u001B[1;32m      5\u001B[0m pivot_df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_Month\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(col[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mint\u001B[39m(col[\u001B[38;5;241m1\u001B[39m])) \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m pivot_df\u001B[38;5;241m.\u001B[39mcolumns]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Limit the feature matrix to Santa Fe",
   "id": "307984345279050a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:33.380233Z",
     "start_time": "2024-08-02T08:45:33.365059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "single_state_df = pivot_df[pivot_df['State'] == 'SANTA FE']\n",
    "single_state_df.head()"
   ],
   "id": "6bc61c7d2eff77de",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pivot_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m single_state_df \u001B[38;5;241m=\u001B[39m \u001B[43mpivot_df\u001B[49m[pivot_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSANTA FE\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      2\u001B[0m single_state_df\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pivot_df' is not defined"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:33.939234Z",
     "start_time": "2024-08-02T08:45:33.924926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(single_state_df.shape)\n",
    "print(\"Dropping na...\")\n",
    "single_state_df = single_state_df.dropna()\n",
    "print(single_state_df.shape)"
   ],
   "id": "2d3b8d9fd14c6c4",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'single_state_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43msingle_state_df\u001B[49m\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDropping na...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m single_state_df \u001B[38;5;241m=\u001B[39m single_state_df\u001B[38;5;241m.\u001B[39mdropna()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'single_state_df' is not defined"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Training",
   "id": "40a5b105d2d2e07"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 Fit an LR model",
   "id": "71d8cf3443375358"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:35.602134Z",
     "start_time": "2024-08-02T08:45:35.585710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the data\n",
    "df = single_state_df\n",
    "\n",
    "# Splitting the data into features and target\n",
    "X = df.drop(columns=['Year', 'State', 'Value'])\n",
    "y = df['Value']\n",
    "years = df['Year']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, years_train, years_test = train_test_split(X, y, years, test_size=0.2, random_state=42)"
   ],
   "id": "a9e19dfd96f13d0d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'single_state_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Prepare the data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43msingle_state_df\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Splitting the data into features and target\u001B[39;00m\n\u001B[1;32m      5\u001B[0m X \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mState\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValue\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'single_state_df' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:36.410595Z",
     "start_time": "2024-08-02T08:45:36.396738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fit LR model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)"
   ],
   "id": "2095658c32fa5f9d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Fit LR model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m lr_model \u001B[38;5;241m=\u001B[39m LinearRegression()\n\u001B[0;32m----> 3\u001B[0m lr_model\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train\u001B[49m, y_train)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:37.016883Z",
     "start_time": "2024-08-02T08:45:37.013048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model as pickle file\n",
    "with open('linear_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)"
   ],
   "id": "41a426dc0b59a00b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:37.633208Z",
     "start_time": "2024-08-02T08:45:37.629989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the pickle file (for testing purposes)\n",
    "with open('linear_regression.pkl', 'rb') as f:\n",
    "    lr_model = pickle.load(f)"
   ],
   "id": "f0ef147e5973367",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.4 Inspect the LR model",
   "id": "47744b738c3b5549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T08:45:38.767450Z",
     "start_time": "2024-08-02T08:45:38.753088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predicting with Linear Regression\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "print(f'Linear Regression Test MSE: {lr_mse}')\n",
    "\n",
    "# Compare predictions\n",
    "print(f'Linear Regression Predictions: {lr_predictions[:5]}')\n",
    "\n",
    "# Calculate metrics for Linear Regression\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Linear Regression - MSE: {lr_mse}, R²: {lr_r2}, MAE: {lr_mae}')\n",
    "\n",
    "# Plotting the predictions\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot for Linear Regression\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, lr_predictions, alpha=0.7, label='Predictions')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Linear Regression Predictions')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ec6789a5709684cb",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Predicting with Linear Regression\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m lr_predictions \u001B[38;5;241m=\u001B[39m lr_model\u001B[38;5;241m.\u001B[39mpredict(\u001B[43mX_test\u001B[49m)\n\u001B[1;32m      3\u001B[0m lr_mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, lr_predictions)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLinear Regression Test MSE: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlr_mse\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "120b442778861fd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
