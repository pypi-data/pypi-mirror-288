Metadata-Version: 2.1
Name: samv2
Version: 0.0.2
Summary: fork of the official SAMv2 implementation with cpu support
Keywords: deep-learning,pytorch
Author-email: Saurav Maheshkar <sauravvmaheshkar@gmail.com>
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.3.1
Requires-Dist: torchvision>=0.18.1
Requires-Dist: numpy>=1.24.4
Requires-Dist: tqdm>=4.66.1
Requires-Dist: hydra-core>=1.3.2
Requires-Dist: iopath>=0.1.10
Requires-Dist: pillow>=9.4.0
Requires-Dist: samv2[test,dev] ; extra == "all"
Requires-Dist: black ; extra == "dev"
Requires-Dist: isort ; extra == "dev"
Requires-Dist: pre-commit>=2.18.0 ; extra == "dev"
Requires-Dist: pytest ; extra == "test"
Project-URL: homepage, https://github.com/SauravMaheshkar/samv2
Project-URL: repository, https://github.com/SauravMaheshkar/samv2
Provides-Extra: all
Provides-Extra: dev
Provides-Extra: test

## Installation

This is a CPU compatible fork of the official SAMv2 implementation. You can download it from [pypi](https://pypi.org/) using `pip` as follows:

```bash
pip install samv2
```

## Usage

After downloading the official weights, you can use the `load_model()` helper method to instantiate a model.

```python
from sam2 import load_model

model = load_model(
    variant="tiny",
    ckpt_path="artifacts/sam2_hiera_tiny.pt",
    device="cpu"
)
```

## Features ðŸš€

* CPU compatible
* ships with config files

## Citation

```bibtex
@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint},
  year={2024}
}
```

