{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discrete unit model\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/hubert/km200/km.bin\n",
    "# tts model\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/hubert/tts_km200/tts_checkpoint_best.pt\n",
    "# waveglow\n",
    "!wget https://dl.fbaipublicfiles.com/textless_nlp/gslm/waveglow_256channels_new.pt\n",
    "# download dummpy speech\n",
    "!wget https://keithito.com/LJ-Speech-Dataset/LJ037-0171.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install transformers asrp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "import joblib\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy\n",
    "from transformers import Wav2Vec2FeatureExtractor, HubertModel\n",
    "\n",
    "\n",
    "class HubertCode(object):\n",
    "    def __init__(self, hubert_model, km_path, km_layer, return_diff=False, sampling_rate=16000):\n",
    "        self.processor = Wav2Vec2FeatureExtractor.from_pretrained(hubert_model)\n",
    "        self.model = HubertModel.from_pretrained(hubert_model)\n",
    "        self.model.eval()\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.km_model = joblib.load(km_path)\n",
    "        self.km_layer = km_layer\n",
    "        self.return_diff = return_diff\n",
    "        self.C_np = self.km_model.cluster_centers_.transpose()\n",
    "        self.Cnorm_np = (self.C_np ** 2).sum(0, keepdims=True)\n",
    "\n",
    "        self.C = torch.from_numpy(self.C_np)\n",
    "        self.Cnorm = torch.from_numpy(self.Cnorm_np)\n",
    "        if torch.cuda.is_available():\n",
    "            self.C = self.C.cuda()\n",
    "            self.Cnorm = self.Cnorm.cuda()\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "    def __call__(self, filepath, merge=True):\n",
    "        with torch.no_grad():\n",
    "            speech, sr = torchaudio.load(filepath)\n",
    "            if sr != self.sampling_rate:\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.sampling_rate)\n",
    "                speech = resampler.forward(speech.squeeze(0)).numpy()\n",
    "            else:\n",
    "                speech = speech.squeeze(0).numpy()\n",
    "            input_values = self.processor(speech, return_tensors=\"pt\", sampling_rate=self.sampling_rate).input_values\n",
    "            if torch.cuda.is_available():\n",
    "                input_values = input_values.cuda()\n",
    "            hidden_states = self.model(input_values, output_hidden_states=True).hidden_states\n",
    "            x = hidden_states[self.km_layer].squeeze()\n",
    "            dist = torch.sqrt(\n",
    "                x.pow(2).sum(1, keepdim=True)\n",
    "                - 2 * torch.matmul(x, self.C)\n",
    "                + self.Cnorm\n",
    "            )\n",
    "            # top K == 6\n",
    "            min_dist = torch.topk(dist.detach(), 6, dim=-1,largest=False)\n",
    "            pred_ind_array = min_dist.indices.cpu().numpy()\n",
    "            pred_values_array = min_dist.values.cpu().numpy()\n",
    "            greedy_output = min_dist.indices.T.cpu().numpy()[0]\n",
    "            print(\"greedy length\", len(greedy_output))\n",
    "            greedy_output = [k for k,_ in groupby(greedy_output)]\n",
    "            print(\"greedy merged length\", len(greedy_output))\n",
    "\n",
    "            sequences = [[[], 1.0]]\n",
    "            for i_row,v_row in zip(pred_ind_array,pred_values_array):\n",
    "                all_candidates = list()\n",
    "                exceed = False\n",
    "                for seq in sequences:\n",
    "                    tokens, score = seq\n",
    "                    for k,v in zip(i_row,v_row):\n",
    "                        norm_len_rate = (len([k for k,_ in groupby(tokens + [k])])/len(greedy_output))\n",
    "                        norm_dist_rate = (v/numpy.sum(v_row))\n",
    "                        candidate = [tokens + [k], score + norm_len_rate * norm_dist_rate]\n",
    "                        all_candidates.append(candidate)\n",
    "                ordered = sorted(all_candidates, key=lambda tup: tup[1],reverse=False)\n",
    "                sequences = ordered[:200]\n",
    "            # top beamsearch result\n",
    "            unitcode = [k for k,_ in groupby(sequences[0][0])]\n",
    "            if self.return_diff:\n",
    "                return unitcode, x.cpu() - torch.index_select(torch.tensor(self.C_np.transpose()).cpu(), 0, min_dist.indices.cpu())\n",
    "            else:\n",
    "                return unitcode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hc = HubertCode(\"facebook/hubert-base-ls960\", './km.bin', 6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code = hc('LJ037-0171.wav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(code)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asrp\n",
    "cs = asrp.Code2Speech(tts_checkpoint='./tts_checkpoint_best.pt', waveglow_checkpint='waveglow_256channels_new.pt', end_tok=201, code_begin_pad=1)\n",
    "\n",
    "# play on notebook\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(data=cs(code), autoplay=False, rate=cs.sample_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}