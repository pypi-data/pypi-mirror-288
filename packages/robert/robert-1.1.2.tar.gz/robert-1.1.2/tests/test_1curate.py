#!/usr/bin/env python

######################################################.
# 	        Testing CURATE with pytest 	             #
######################################################.

import os
import glob
import pytest
import shutil
import subprocess
import pandas as pd

# saves the working directory
path_tests = os.getcwd() + "/tests"
path_curate = os.getcwd() + "/CURATE"

# CURATE tests
@pytest.mark.parametrize(
    "test_job",
    [
        (
            "categorical"
        ),  # categorical with numbers test
        (
            "nan_fix"
        ),  # test that empty values are replaced by 0s
        (
            "corr_filter"
        ),  # test to disable the correlation filter
        (
            "filter_thres"
        ),  # test to check the thresholds of the correlation filters
        (
            "filter_thres_yaml"
        ),  # test to check the thresholds of the correlation filters with a yaml file  
        (
            "csv_separator"
        ),  # test to check the separator of the CSV file
        (
            "standard"
        ),  # standard test  

    ],
)
def test_CURATE(test_job):

    # leave the folders as they were initially to run a different batch of tests
    if os.path.exists(f"{path_curate}"):
        shutil.rmtree(f"{path_curate}")
        # remove DAT and CSV files generated by CURATE
        dat_files = glob.glob("*.dat")
        for dat_file in dat_files:
            if "CURATE" in dat_file:
                os.remove(dat_file)

    # runs the program with the different tests
    cmd_robert = [
        "python",
        "-m",
        "robert",
        "--curate",
        "--csv_name", f"{path_tests}/Robert_example.csv",
        '--y', 'Target_values',
        "--ignore", "['Name']",
        "--discard", "['xtest']"
    ]

    if test_job == "standard":
        subprocess.run(cmd_robert)

        # check that the DAT file is created inside the CURATE folder
        assert not os.path.exists("CURATE_data.dat")
        outfile = open(f"{path_curate}/CURATE_data.dat", "r")
        outlines = outfile.readlines()
        outfile.close()
        assert "ROBERT v" in outlines[0]

        # check that descriptors are removed correctly
        db_final = pd.read_csv(f"{path_curate}/Robert_example_CURATE.csv")
        # 1. Duplicate entries are removed
        assert len(db_final['Name']) == 37
        # 2. Correlated variables with X and noise (low R2 with y) are removed
        discard_vars = ['x1','x3','ynoise']
        for var in discard_vars:
            assert var not in db_final.columns
        # 3. Ignored variables and y are kept
        assert 'Name' in db_final.columns
        assert 'Target_values' in db_final.columns
        # 4. Discarded variables are removed
        assert 'xtest' not in db_final.columns
        # 5. The rest of the variables are kept
        final_vars = ['x2','x5','x6','x7','x8','x9','x10','x11']
        for var in final_vars:
            assert var in db_final.columns

        # check that categorical variables are converted with one-hot encoding
        categ_vars = ['Csub-H','Csub-Csub','H-O','Csub-O']
        for var in categ_vars:
            assert var in db_final.columns
        assert 'x4' not in db_final.columns
        for val in db_final['Csub-H']:
            assert val in [0,1]

        # check that the CURATE options are stored
        db_save = pd.read_csv(f"{path_curate}/CURATE_options.csv")
        assert db_save['y'][0] == "Target_values"
        assert db_save['ignore'][0] == "['Name']"
        assert 'Robert_example_CURATE.csv' in db_save['csv_name'][0]

        #check that the Pearson heatplot is created
        assert os.path.exists(f'{path_curate}/Pearson_heatmap.png')

        # Check if the descriptors were reduced correctly (less than 1/3 of the data points)
        db_final = pd.read_csv(f"{path_curate}/Robert_example_CURATE.csv")
        n_descps = len(db_final.columns) - 2  # subtracting 'Name' and 'Target_values'
        datapoints = len(db_final)
        assert n_descps < (datapoints / 3)

    elif test_job == "categorical":
        cmd_robert = cmd_robert + ['--categorical', 'numbers']
        subprocess.run(cmd_robert)

        # check if variable x4 was changed
        db_final = pd.read_csv(f"{path_curate}/Robert_example_CURATE.csv")
        assert 'x4' in db_final.columns
        assert 3 in db_final['x4']

    elif test_job == "nan_fix":
        cmd_robert = [
            "python",
            "-m",
            "robert",
            "--curate",
            "--csv_name", f"{path_tests}/Robert_example_NaNs.csv",
            '--y', 'Target_values',
            "--ignore", "['Name']",
            "--discard", "['xtest']"
        ]
        subprocess.run(cmd_robert)

        # check that all the missing values were filled with 0s
        db_final = pd.read_csv(f"{path_curate}/Robert_example_NaNs_CURATE.csv")
        # 1. Duplicate entries are removed
        assert db_final['x3'][0] == 0
        assert db_final['x3'][8] == 0

    elif test_job == 'corr_filter':
        cmd_robert = [
            "python",
            "-m",
            "robert",
            "--curate",
            "--csv_name", f"{path_tests}/Robert_example.csv",
            '--y', 'Target_values',
            "--ignore", "['Name']",
            "--discard", "['xtest']",
            "--corr_filter", "False"
        ]
        subprocess.run(cmd_robert)
        
        # check that descriptors aren't removed 
        db_final = pd.read_csv(f"{path_curate}/Robert_example_CURATE.csv")
        discard_vars = ['x1','x3','ynoise']
        for var in discard_vars:
            assert var in db_final.columns

    elif test_job in ['filter_thres','filter_thres_yaml']:
        if test_job == 'filter_thres':
            cmd_robert = [
                "python",
                "-m",
                "robert",
                "--curate",
                "--csv_name", f"{path_tests}/Robert_example.csv",
                '--y', 'Target_values',
                "--ignore", "['Name']",
                "--discard", "['xtest']",
                "--thres_x", "0.999",
                "--thres_y", "0.000001"
            ]
        elif test_job == 'filter_thres_yaml':
            cmd_robert = [
                "python",
                "-m",
                "robert",
                "--varfile", f"{path_tests}/params.yaml",
                "--csv_name", f"{path_tests}/Robert_example.csv",
            ]
        subprocess.run(cmd_robert)
        
        # check that descriptors aren't removed
        db_final = pd.read_csv(f"{path_curate}/Robert_example_CURATE.csv")
        # check x threshold
        assert 'x1' in db_final.columns
        # check y threshold
        assert 'ynoise' in db_final.columns

    elif test_job == 'csv_separator':
        # Test to check if the separator of the CSV file is correctly read
        cmd_robert = [
            "python",
            "-m",
            "robert",
            "--curate",
            "--csv_name", f"{path_tests}/Robert_example_separator.csv",
            '--y', 'Target_values',
            "--ignore", "['Name']",
            "--discard", "['xtest']"
        ]
        subprocess.run(cmd_robert)

        # check that the DAT file has a warning about the separator
        assert not os.path.exists("CURATE_data.dat")
        outfile = open(f"{path_curate}/CURATE_data.dat", "r")
        outlines = outfile.readlines()
        outfile.close()
        assert "x  WARNING! The original database was not a valid CSV (i.e., formatting issues from Microsoft Excel?)." in outlines[8]

        # check that the CSV file has the correct separator
        csv_file = pd.read_csv(f"{path_tests}/Robert_example_separator_original.csv", sep=";")
        csv_file_new = pd.read_csv(f"{path_tests}/Robert_example_separator.csv", sep=",")
        assert csv_file.equals(csv_file_new)